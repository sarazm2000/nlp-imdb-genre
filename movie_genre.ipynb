{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9141d81",
   "metadata": {},
   "source": [
    "# determine genre of the movies\n",
    "## natural process langueges on imdb movies\n",
    "\n",
    "### Sara Zahedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946792c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import tqdm\n",
    "import nltk, re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0505f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('dataset.json')\n",
    "data = json.load(f)\n",
    "# for i in data[0:5]:\n",
    "#     print(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a8133",
   "metadata": {},
   "source": [
    "### get number of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243793e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of movies data: 1878\n"
     ]
    }
   ],
   "source": [
    "print(\"number of movies data:\",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e5aa5",
   "metadata": {},
   "source": [
    "### count all storyline words and senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02b6b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total storyline words: 177601\n",
      "total storyline tences: 8962\n"
     ]
    }
   ],
   "source": [
    "words_counter = 0\n",
    "sentence_counter = 0\n",
    "\n",
    "for d in data:\n",
    "    for sl in d[\"storyline\"]:\n",
    "        num_words = sl.split()\n",
    "        words_counter += len(num_words)\n",
    "        num_sentence = sl.split(\". \")\n",
    "        sentence_counter += len(num_sentence)\n",
    "print(\"total storyline words:\", words_counter)\n",
    "print(\"total storyline tences:\", sentence_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8aedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c927f79",
   "metadata": {},
   "source": [
    "### normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136724f",
   "metadata": {},
   "source": [
    "get and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b103903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a875c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = text.lower()\n",
    "    return [x for x in nltk.word_tokenize(text) if x not in stopwords and x not in string.punctuation]\n",
    "\n",
    "cleaned_tokens = [remove_stopwords(' '.join([str(elem) for elem in x['storyline']])) for x in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dc220ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 1878\n"
     ]
    }
   ],
   "source": [
    "tokens_len = len(cleaned_tokens)\n",
    "print(\"number of tokens:\",tokens_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d156ba",
   "metadata": {},
   "source": [
    "Stemm tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9a1395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer  = PorterStemmer()\n",
    "\n",
    "l = len(cleaned_tokens)\n",
    "for i in range(l):\n",
    "    elment_len = len(cleaned_tokens[i])\n",
    "    for w in range(elment_len):\n",
    "        cleaned_tokens[i][w] = (stemmer.stem(cleaned_tokens[i][w]))\n",
    "# cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ea36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff7eab8b",
   "metadata": {},
   "source": [
    "lemmatizing tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f1e5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(l):\n",
    "    elment_len = len(cleaned_tokens[i])\n",
    "    for w in range(elment_len):\n",
    "        cleaned_tokens[i][w] = (lemmatizer.lemmatize(cleaned_tokens[i][w]))\n",
    "\n",
    "# cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b890b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_len = len(cleaned_tokens)\n",
    "for i in range(tokens_len):\n",
    "    cleaned_tokens[i] = [item for item in cleaned_tokens[i] if len(item)>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0fd3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print some tokens:\n",
      " [['riddler', 'sadist', 'serial', 'killer', 'begin', 'murder', 'polit', 'figur', 'gotham', 'batman', 'forc', 'investig', 'citi', 'hidden', 'corrupt', 'question', 'famili', 'involv', 'riddler', 'sadist', 'serial', 'killer', 'begin', 'murder', 'polit', 'figur', 'gotham', 'batman', 'forc', 'investig', 'citi', 'hidden', 'corrupt', 'question', 'famili', 'involv', 'riddler', 'sadist', 'serial', 'killer', 'begin', 'murder', 'polit', 'figur', 'gotham', 'batman', 'forc', 'investig', 'citi', 'hidden', 'corrupt', 'question', 'famili', 'involv'], ['visionari', 'director', 'robert', 'egger', 'come', 'northman', 'action-fil', 'epic', 'follow', 'young', 'vike', 'princ', 'quest', 'aveng', 'father', 'murder', 'visionari', 'director', 'robert', 'egger', 'come', 'northman', 'action-fil', 'epic', 'follow', 'young', 'vike', 'princ', 'quest', 'aveng', 'father', 'murder', 'visionari', 'director', 'robert', 'egger', 'come', 'northman', 'action-fil', 'epic', 'follow', 'young', 'vike', 'princ', 'quest', 'aveng', 'father', 'murder'], ['seri', 'follow', 'steven', 'grant', 'mild-', 'manner', 'gift-shop', 'employe', 'becom', 'plagu', 'blackout', 'memori', 'anoth', 'life', 'steven', 'discov', 'dissoci', 'ident', 'disord', 'share', 'bodi', 'mercenari', 'marc', 'spector', 'steven/marc', 'enemi', 'converg', 'upon', 'must', 'navig', 'complex', 'ident', 'thrust', 'deadli', 'mysteri', 'among', 'power', 'egypt', 'seri', 'follow', 'steven', 'grant', 'mild-', 'manner', 'gift-shop', 'employe', 'becom', 'plagu', 'blackout', 'memori', 'anoth', 'life', 'steven', 'discov', 'dissoci', 'ident', 'disord', 'share', 'bodi', 'mercenari', 'marc', 'spector', 'steven/marc', 'enemi', 'converg', 'upon', 'must', 'navig', 'complex', 'ident', 'thrust', 'deadli', 'mysteri', 'among', 'power', 'egypt', 'seri', 'follow', 'steven', 'grant', 'mild-', 'manner', 'gift-shop', 'employ', 'becom', 'plagu', 'blackout', 'memori', 'anoth', 'life', 'steven', 'discov', 'dissoci', 'ident', 'disord', 'share', 'bodi', 'mercenari', 'marc', 'spector', 'steven/marc', 'enemi', 'converg', 'upon', 'must', 'navig', 'complex', 'ident', 'thrust', 'deadli', 'mysteri', 'among', 'power', 'egypt']]\n"
     ]
    }
   ],
   "source": [
    "print(\"print some tokens:\\n\" , cleaned_tokens[0:3][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd2812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1878"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extend_story(tokens):\n",
    "    return tokens + [lemmatizer.lemmatize(x) for x in tokens] + [stemmer.stem(x) for x in tokens]\n",
    "\n",
    "cleaned_tokens = [extend_story(x) for x in cleaned_tokens]\n",
    "len(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3b99f",
   "metadata": {},
   "source": [
    "#### labelling words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e93b61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_words = dict(enumerate(set(sum(cleaned_tokens, []))))\n",
    "dict_words = dict((y, x) for x, y in inv_words.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dba7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"print some dict words:\", dict_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d0b76",
   "metadata": {},
   "source": [
    "#### labelling genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f99241b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_label = dict(enumerate(set(sum([x['genre'] for x in data], []))))\n",
    "dict_label = dict((y, x) for x, y in inv_label.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ea60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"print some dict label:\", dict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5432a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim words 12717\n",
      "dim level 27\n"
     ]
    }
   ],
   "source": [
    "dim_words = len(dict_words)\n",
    "dim_level = len(dict_label)\n",
    "print(\"dim words\", dim_words)\n",
    "print(\"dim level\", dim_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4d644",
   "metadata": {},
   "source": [
    "create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "824ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for row in data:\n",
    "    story, label = row['storyline'], row['genre']\n",
    "    vector = [0] * dim_words\n",
    "    story = ' '.join(map(str, story)).lower()\n",
    "\n",
    "    tokens = [dict_words.get(x) for x in nltk.word_tokenize(story)]\n",
    "    tokens = [x for x in tokens if x]\n",
    "    labels = [dict_label.get(x) for x in label]\n",
    "    labels = [x for x in labels if x]\n",
    "    \n",
    "    for ind in tokens:\n",
    "        vector[ind] += 1\n",
    "    \n",
    "    vector = np.array(vector)\n",
    "    vector = vector / np.linalg.norm(vector)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    vector = [vector, labels]\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8e25256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0., 0., 0., ..., 0., 0., 0.]), array([10, 14])]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1878"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectors[0:1])\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e67108",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3717d",
   "metadata": {},
   "source": [
    "### Give a storyline and get the genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d090b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drama', 'Thriller']\n"
     ]
    }
   ],
   "source": [
    "text = \"John Rambo is offered the chance to cut short his prison tenure by going on a secret mission for the US government deep into the jungles of Vietnam and locating American POWs.\"\n",
    "text = \"Set in Albuquerque, New Mexico, between 2008 and 2010, Breaking Bad follows Walter White, a meek high school chemistry teacher who transforms into a ruthless player in the local methamphetamine drug trade, driven by a desire to financially provide for his family after being diagnosed with terminal lung cancer\"\n",
    "threshold = 0.15\n",
    "\n",
    "def perdict(_text, _vectors):\n",
    "    \n",
    "    tokens = remove_stopwords(_text.lower())\n",
    "\n",
    "    tokens = [dict_words.get(x) for x in extend_story(tokens)]\n",
    "    tokens = [x for x in tokens if x]\n",
    "#     print(\"tokens\" + tokens[0])\n",
    "    \n",
    "    inp_vector = [0] * dim_words\n",
    "    \n",
    "    for ind in tokens:\n",
    "        inp_vector[ind] += 1\n",
    "    \n",
    "    inp_vector = np.array(inp_vector)\n",
    "    inp_vector = inp_vector / np.linalg.norm(inp_vector)\n",
    "    \n",
    "    labels = []\n",
    "    for vec, lab in _vectors:\n",
    "        res = np.dot(vec, inp_vector)\n",
    "        if res >= 1 - threshold:\n",
    "            labels.extend(lab)\n",
    "    return list(dict.fromkeys([inv_label[x] for x in labels]))\n",
    "\n",
    "genre_len = len(perdict(text, vectors))\n",
    "\n",
    "while(genre_len == 0):\n",
    "    if (genre_len > 0.95):\n",
    "        print(\"not found!\")\n",
    "        break\n",
    "    threshold += 0.05\n",
    "    genre_len = len(perdict(text, vectors))\n",
    "    \n",
    "print(perdict(text, vectors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
